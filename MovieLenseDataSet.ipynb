{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "dataFile=\"/Users/Prince.Bharti/Desktop/csv/ml-100k/u.data\"\n",
    "data=pd.read_csv(dataFile,sep=\"\\t\",header=None,names=['userId','itemId','rating','timestamp'])\n",
    "\n",
    "userInfoFile=\"/Users/Prince.Bharti/Desktop/csv/ml-100k/u.user\"\n",
    "userInfo=pd.read_csv(userInfoFile,sep=\"|\",header=None,index_col=False,names=['userId','age','gender','occupation','zip code'])\n",
    "\n",
    "movieInfoFile=\"/Users/Prince.Bharti/Desktop/csv/ml-100k/u.item\"\n",
    "movieInfo=pd.read_csv(movieInfoFile,header=None,sep=\"|\",index_col=False,names=['itemId','title'],usecols=[0,1],encoding = \"ISO-8859-1\") #encoding has been used because it was giving some kind of parsing error via stack overflow\n",
    "\n",
    "#basically we will use only data and movie info by merging(~ sql join) both dataframes.\n",
    "data=pd.merge(data,movieInfo,left_on='itemId',right_on='itemId')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method to calculate top n movies rated  by a  user ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topNMovies(n,activeUser):\n",
    "    movies=data[data.userId==activeUser].sort_values(by=['rating'],ascending=[0]).title[0:n]\n",
    "    return list(movies)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "### neighbourhood based collaborative filtering approach for recommending movies to a particular user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### For a neighbourhood based collaborative approach basically we deal with two methods/functions.\n",
    "1.finding k nearest neighbours which are similar to the active users.\n",
    "\n",
    "2.Prediced rating matrix with the help of k nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataFile=\"/Users/Prince.Bharti/Desktop/csv/ml-100k/u.data\"\n",
    "data=pd.read_csv(dataFile,sep=\"\\t\",header=None,names=['userId','itemId','rating','timestamp'])\n",
    "userInfoFile=\"/Users/Prince.Bharti/Desktop/csv/ml-100k/u.user\"\n",
    "userInfo=pd.read_csv(userInfoFile,sep=\"|\",header=None,index_col=False,names=['userId','age','gender','occupation','zip code'])\n",
    "\n",
    "movieInfoFile=\"/Users/Prince.Bharti/Desktop/csv/ml-100k/u.item\"\n",
    "movieInfo=pd.read_csv(movieInfoFile,header=None,sep=\"|\",index_col=False,names=['itemId','title'],usecols=[0,1],encoding = \"ISO-8859-1\") #encoding has been used because it was giving some kind of parsing error via stack overflow\n",
    "\n",
    "#basically we will use only data and movie info by merging(~ sql join) both dataframes.\n",
    "data=pd.merge(data,movieInfo,left_on='itemId',right_on='itemId')\n",
    "userItemRatingMatrix=pd.pivot_table(data,index='userId',values='rating',columns='itemId')\n",
    "\n",
    "\n",
    "\n",
    "from scipy import spatial\n",
    "def similarity(userItemRatingMatrix,user1, user2):\n",
    "    commonItemList=[i for i in range(0,len(userItemRatingMatrix)) if user1[i]>0 and user2[i]>0]\n",
    "    user1=np.array(user1[commonItemList])\n",
    "    user2=np.array(user2[commonItemList])\n",
    "    if(len(commonItemList)==0):\n",
    "        return 0\n",
    "    else:\n",
    "        return  spatial.distance.correlation(user1,user2)\n",
    "\n",
    "def nearestNeighbours(userItemRatingMatrix,activeUser,k):\n",
    "#     for storing id and similarity value of k neighbours\n",
    "    similarMatrix=pd.DataFrame(index=userItemRatingMatrix.index,columns=['similarity'])\n",
    "    \n",
    "#   iterating for each user in the userItemMatrix and finding the similarity with the \n",
    "#   active user and then storing in the similarMatrix\n",
    "    for i in userItemRatingMatrix.index:\n",
    "        user1=np.array(userItemRatingMatrix.loc[i])\n",
    "        user2=np.array(userItemRatingMatrix.loc[activeUser])\n",
    "        similarMatrix.loc[i,'similarity']=similarity(userItemRatingMatrix,user1,user2)\n",
    "        similarMatrix=similarMatrix.sort_values(by=['similarity'],ascending=True)\n",
    "    return similarMatrix[1:5]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/spatial/distance.py:364: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(um, vm) / (norm(um) * norm(vm))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>-2.22045e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-2.22045e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         similarity\n",
       "userId             \n",
       "607    -2.22045e-16\n",
       "426    -2.22045e-16\n",
       "237               0\n",
       "571               0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearestNeighboursData=nearestNeighbours(userItemRatingMatrix,2,5)\n",
    "userItemRatingMatrix[nearestNeighbours.in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/f2b69c2dbc4f969722043de21a27814b"
  },
  "gist": {
   "data": {
    "description": "MovieLense DataSet.ipynb",
    "public": false
   },
   "id": "f2b69c2dbc4f969722043de21a27814b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
